
/**
 * üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–†–û–ë–õ–ï–ú –¢–û–ö–ï–ù–ò–ó–ê–¶–ò–ò
 * –ê–Ω–∞–ª–∏–∑ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º —Å UNK —Ç–æ–∫–µ–Ω–∞–º–∏
 */

const { BooomerangsNeuralCore } = require('./server/neural-network-core.cjs');

async function debugTokenization() {
  console.log('üîç –ó–∞–ø—É—Å–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏...');
  
  try {
    const neural = new BooomerangsNeuralCore();
    await neural.initialize();
    
    // –¢–µ—Å—Ç–æ–≤—ã–µ —Ñ—Ä–∞–∑—ã
    const testPhrases = [
      '—á—Ç–æ —Ç–∞–∫–æ–µ —Å–≤–µ–∂–æ—Å—Ç—å',
      '–∫–∞–∫ –¥–µ–ª–∞',
      '—Å–æ–∑–¥–∞–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ',
      'booomerangs ai —Å–∏—Å—Ç–µ–º–∞'
    ];
    
    console.log('\nüìù –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏...');
    
    for (const phrase of testPhrases) {
      console.log(`\nüéØ –§—Ä–∞–∑–∞: "${phrase}"`);
      
      // –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
      const tokens = neural.tokenize(phrase);
      console.log(`üìä –¢–æ–∫–µ–Ω—ã: [${tokens.join(', ')}]`);
      
      // –î–µ—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
      const detokenized = neural.detokenize(tokens);
      console.log(`üîÑ –î–µ—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è: "${detokenized}"`);
      
      // –ê–Ω–∞–ª–∏–∑ UNK —Ç–æ–∫–µ–Ω–æ–≤
      const unkCount = detokenized.split('<UNK>').length - 1;
      const totalWords = phrase.split(' ').length;
      const unkRatio = unkCount / totalWords;
      
      console.log(`üìà UNK –∞–Ω–∞–ª–∏–∑: ${unkCount}/${totalWords} (${(unkRatio * 100).toFixed(1)}%)`);
      
      if (unkRatio > 0.3) {
        console.log('‚ùå –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç UNK —Ç–æ–∫–µ–Ω–æ–≤!');
      } else {
        console.log('‚úÖ UNK —Ç–æ–∫–µ–Ω—ã –≤ –Ω–æ—Ä–º–µ');
      }
    }
    
    // –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–ª–æ–≤–∞—Ä–µ–π
    console.log('\nüìö –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–ª–æ–≤–∞—Ä–µ–π:');
    console.log(`   vocabulary —Ä–∞–∑–º–µ—Ä: ${neural.vocabulary.size}`);
    console.log(`   reverseVocabulary —Ä–∞–∑–º–µ—Ä: ${neural.reverseVocabulary.size}`);
    console.log(`   vocabSize: ${neural.vocabSize}`);
    
    // –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–≤—ã—Ö 10 —Ç–æ–∫–µ–Ω–æ–≤
    console.log('\nüîç –ü–µ—Ä–≤—ã–µ 10 —Ç–æ–∫–µ–Ω–æ–≤:');
    for (let i = 0; i < 10; i++) {
      const word = neural.reverseVocabulary.get(i);
      const index = neural.vocabulary.get(word);
      console.log(`   ${i}: "${word}" -> ${index} ${index === i ? '‚úÖ' : '‚ùå'}`);
    }
    
  } catch (error) {
    console.error('‚ùå –û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏:', error);
  }
}

// –ó–∞–ø—É—Å–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
debugTokenization();
